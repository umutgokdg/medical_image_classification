{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umutg\\AppData\\Local\\Temp\\ipykernel_22184\\479934303.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['diagnostic'] = data['diagnostic'].map({'BCC': 1, 'MEL': 1, 'SCC':1, 'ACK': 0, 'NEV': 0, 'SEK': 0})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "image_dir = 'images/imgs_part_1/imgs_part_1/'\n",
    "image_files = set(os.listdir(image_dir))\n",
    "\n",
    "def image_exists(img_id):\n",
    "    return img_id in image_files\n",
    "\n",
    "metadata['image_exists'] = metadata['img_id'].apply(image_exists)\n",
    "metadata_filtered = metadata[metadata['image_exists']]\n",
    "metadata_filtered = metadata_filtered.drop(columns=['image_exists'])\n",
    "metadata_filtered.to_csv('filtered_metadata.csv', index=False)\n",
    "metadata = pd.read_csv('filtered_metadata.csv')\n",
    "\n",
    "# Filter relevant columns and map diagnostic to binary cancer labels\n",
    "data = metadata[[\n",
    "                #'background_father', 'background_mother','gender',  'biopsed' \n",
    "                 'age', 'img_id', 'diagnostic'\n",
    "                 ,'smoke', 'drink', 'skin_cancer_history', 'cancer_history', 'has_piped_water', 'has_sewage_system'\n",
    "                 , 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation'\n",
    "                 ]]\n",
    "data['diagnostic'] = data['diagnostic'].map({'BCC': 1, 'MEL': 1, 'SCC':1, 'ACK': 0, 'NEV': 0, 'SEK': 0})\n",
    "                                               #1,      0.8       0.6       0.4       0.2        0\n",
    "data = data.dropna(subset=['diagnostic'])\n",
    "\n",
    "data['image_path'] = image_dir + data['img_id']\n",
    "#data['background_father'] = data['background_father'].astype('category').cat.codes\n",
    "#data['background_mother'] = data['background_mother'].astype('category').cat.codes\n",
    "#data['biopsed'] = data['biopsed'].astype('category').cat.codes\n",
    "#data['gender'] = data['gender'].astype('category').cat.codes\n",
    "data['smoke'] = data['smoke'].astype('category').cat.codes\n",
    "data['drink'] = data['drink'].astype('category').cat.codes\n",
    "data['skin_cancer_history'] = data['skin_cancer_history'].astype('category').cat.codes\n",
    "data['cancer_history'] = data['cancer_history'].astype('category').cat.codes\n",
    "data['has_piped_water'] = data['has_piped_water'].astype('category').cat.codes\n",
    "data['has_sewage_system'] = data['has_sewage_system'].astype('category').cat.codes\n",
    "data['region'] = data['region'].astype('category').cat.codes\n",
    "data['itch'] = data['itch'].astype('category').cat.codes\n",
    "data['grew'] = data['grew'].astype('category').cat.codes\n",
    "data['hurt'] = data['hurt'].astype('category').cat.codes\n",
    "data['changed'] = data['changed'].astype('category').cat.codes\n",
    "data['bleed'] = data['bleed'].astype('category').cat.codes\n",
    "data['elevation'] = data['elevation'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X_tabular = data[['age'\n",
    "                #'background_father', 'background_mother',  'biopsed'\n",
    "                  ,'smoke', 'drink', 'skin_cancer_history', 'cancer_history', 'has_piped_water', 'has_sewage_system'\n",
    "                  , 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation'\n",
    "                  ]].values\n",
    "y = data['diagnostic'].values\n",
    "image_paths = data['image_path'].values\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train_tabular, X_val_tabular, y_train, y_val, train_image_paths, val_image_paths = train_test_split(\n",
    "    X_tabular, y, image_paths, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tabular_data, image_paths, labels, transform=None):\n",
    "        self.tabular_data = tabular_data\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        tabular_data = torch.tensor(self.tabular_data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        \n",
    "        return tabular_data, image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the image data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(X_train_tabular, train_image_paths, y_train, transform=transform)\n",
    "val_dataset = CustomDataset(X_val_tabular, val_image_paths, y_val, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalNetwork, self).__init__()\n",
    "        \n",
    "        # ResNet50 model for image data\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final layer\n",
    "        \n",
    "        # Multi Layer Perceptron for tabular data\n",
    "        self.fc_tabular = nn.Sequential(\n",
    "            nn.Linear(14, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined layers\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(2048 + 32, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, tabular_data, images):\n",
    "        img_features = self.resnet(images)\n",
    "        tabular_features = self.fc_tabular(tabular_data)\n",
    "        combined_features = torch.cat((img_features, tabular_features), dim=1)\n",
    "        output = self.fc_combined(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umutg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\umutg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 1/10, Loss: 0.5844\n",
      "Epoch 2/10, Loss: 0.5602\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = MultimodalNetwork().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for tabular_data, images, labels in train_loader:\n",
    "        tabular_data, images, labels = tabular_data.to(device), images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tabular_data, images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * tabular_data.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3122, Accuracy: 0.8587\n",
      "[[410  62]\n",
      " [ 68 380]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tabular_data, images, labels in val_loader:\n",
    "        tabular_data, images, labels = tabular_data.to(device), images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(tabular_data, images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        val_loss += loss.item() * tabular_data.size(0)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_loss = val_loss / len(val_loader.dataset)\n",
    "accuracy = correct / total\n",
    "print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 1378\n",
      "Total validation samples: 920\n",
      "Total training batches: 44\n",
      "Total validation batches: 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total training samples: {len(train_dataset)}')\n",
    "print(f'Total validation samples: {len(val_dataset)}')\n",
    "print(f'Total training batches: {len(train_loader)}')\n",
    "print(f'Total validation batches: {len(val_loader)}')\n",
    "labels\n",
    "predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
