{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 24 4 96 21 13 258\n",
      "128 130\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv('male_train.csv')\n",
    "image_dir = 'images/all_images/'\n",
    "image_files = set(os.listdir(image_dir))\n",
    "\n",
    "BCC_count = 0\n",
    "SCC_count = 0\n",
    "ACK_count = 0\n",
    "NEV_count = 0\n",
    "SEK_count = 0\n",
    "MEL_count = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over the entire DataFrame\n",
    "for diagnostic in metadata['diagnostic']:\n",
    "    if diagnostic == 'BCC':\n",
    "        BCC_count += 1\n",
    "    elif diagnostic == 'SCC':\n",
    "        SCC_count += 1\n",
    "    elif diagnostic == 'ACK':\n",
    "        ACK_count += 1\n",
    "    elif diagnostic == 'NEV':\n",
    "        NEV_count += 1\n",
    "    elif diagnostic == 'SEK':\n",
    "        SEK_count += 1\n",
    "    elif diagnostic == 'MEL':\n",
    "        MEL_count += 1\n",
    "    else:\n",
    "        total -= 1\n",
    "    total += 1\n",
    "\n",
    "# drop the random 620 rows that are diognostic as BCC\n",
    "metadata = metadata[metadata['diagnostic'] != 'BCC']\n",
    "\n",
    "print(BCC_count, SCC_count, MEL_count, ACK_count, NEV_count, SEK_count, total)\n",
    "print(MEL_count + BCC_count + SCC_count, SEK_count + NEV_count + ACK_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original metadata length: 690\n",
      "Male data length: 345\n",
      "Female data length: 345\n",
      "Male train length: 258\n",
      "Male test length: 87\n",
      "Female train length: 258\n",
      "Female test length: 87\n",
      "Total length after splitting: 690\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the dataset\n",
    "metadata = pd.read_csv('final_dataset.csv')\n",
    "print(f\"Original metadata length: {len(metadata)}\")\n",
    "\n",
    "# Check for missing values in the gender column\n",
    "missing_gender = metadata[metadata['gender'] == ' ']\n",
    "#missing_gender_count = missing_gender.sum()\n",
    "#print(f\"Missing gender values: {missing_gender_count}\")\n",
    "\n",
    "# Filter the data by gender\n",
    "maledata = metadata[metadata['gender'] == 'MALE']\n",
    "femaledata = metadata[metadata['gender'] == 'FEMALE']\n",
    "\n",
    "# Print lengths of filtered data\n",
    "print(f\"Male data length: {len(maledata)}\")\n",
    "print(f\"Female data length: {len(femaledata)}\")\n",
    "\n",
    "# Split the male data into training and testing sets\n",
    "male_train, male_test = train_test_split(maledata, test_size=0.25, random_state=42)\n",
    "\n",
    "# Split the female data into training and testing sets\n",
    "female_train, female_test = train_test_split(femaledata, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print lengths of splits\n",
    "print(f\"Male train length: {len(male_train)}\")\n",
    "print(f\"Male test length: {len(male_test)}\")\n",
    "print(f\"Female train length: {len(female_train)}\")\n",
    "print(f\"Female test length: {len(female_test)}\")\n",
    "\n",
    "# Verify total length\n",
    "total_split_length = len(male_train) + len(male_test) + len(female_train) + len(female_test)\n",
    "print(f\"Total length after splitting: {total_split_length}\")\n",
    "\n",
    "# Save the datasets to separate CSV files\n",
    "missing_gender.to_csv('missing.csv', index=False)\n",
    "male_train.to_csv('male_train.csv', index=False)\n",
    "male_test.to_csv('male_test.csv', index=False)\n",
    "female_train.to_csv('female_train.csv', index=False)\n",
    "female_test.to_csv('female_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnostic\n",
      "SEK    188\n",
      "NEV    169\n",
      "ACK    128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the dataset\n",
    "metadata = pd.read_csv('missing.csv')\n",
    "\n",
    "# Separate rows by diagnosis\n",
    "bcc_rows = metadata[metadata['diagnostic'] == 'BCC']\n",
    "ack_rows = metadata[metadata['diagnostic'] == 'ACK']\n",
    "other_rows = metadata[(metadata['diagnostic'] != 'BCC') & (metadata['diagnostic'] != 'ACK')]\n",
    "\n",
    "# Calculate the number of rows to drop for BCC and ACK\n",
    "bcc_to_drop = int(len(bcc_rows) * 3 / 4)\n",
    "ack_to_drop = int(len(ack_rows) * 5 / 7)\n",
    "\n",
    "# Randomly drop the rows\n",
    "bcc_rows_dropped = bcc_rows.sample(n=bcc_to_drop, random_state=42)\n",
    "ack_rows_dropped = ack_rows.sample(n=ack_to_drop, random_state=42)\n",
    "\n",
    "# Get the remaining rows\n",
    "bcc_rows_remaining = bcc_rows.drop(bcc_rows_dropped.index)\n",
    "ack_rows_remaining = ack_rows.drop(ack_rows_dropped.index)\n",
    "\n",
    "# Concatenate the remaining rows to form the balanced dataset\n",
    "balanced_metadata = pd.concat([bcc_rows_remaining, ack_rows_remaining, other_rows])\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_metadata = balanced_metadata.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print the new counts for verification\n",
    "print(balanced_metadata['diagnostic'].value_counts())\n",
    "\n",
    "# Save the balanced dataset\n",
    "balanced_metadata.to_csv('balanced_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original metadata length: 2298\n",
      "Metadata length after removing rows with missing gender: 2298\n",
      "Length of male data after dropping rows: 345\n",
      "Length of female data after dropping rows: 345\n",
      "Number of male rows dropped: 396\n",
      "Number of female rows dropped: 408\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "print(f\"Original metadata length: {len(metadata)}\")\n",
    "\n",
    "# Remove rows with missing gender\n",
    "metadata = metadata.dropna(subset=['gender'])\n",
    "print(f\"Metadata length after removing rows with missing gender: {len(metadata)}\")\n",
    "\n",
    "# Filter the data by gender\n",
    "maledata = metadata[metadata['gender'] == 'MALE']\n",
    "femaledata = metadata[metadata['gender'] == 'FEMALE']\n",
    "\n",
    "# Define the function to drop a specific number of rows according to the given ratio\n",
    "def drop_rows_by_ratio(data, drop_count, drop_ratio, keep_ratio):\n",
    "    total_rows = len(data)\n",
    "    indices_to_drop = []\n",
    "    dropped_count = 0\n",
    "\n",
    "    i = 0\n",
    "    while dropped_count < drop_count:\n",
    "        if i + drop_ratio + keep_ratio <= total_rows and dropped_count + drop_ratio <= drop_count:\n",
    "            indices_to_drop.extend(range(i, i + drop_ratio))\n",
    "            dropped_count += drop_ratio\n",
    "            i += drop_ratio + keep_ratio\n",
    "        else:\n",
    "            # If close to the end, drop remaining needed rows\n",
    "            remaining_to_drop = drop_count - dropped_count\n",
    "            indices_to_drop.extend(range(i, i + remaining_to_drop))\n",
    "            break\n",
    "\n",
    "    return data.drop(data.index[indices_to_drop])\n",
    "\n",
    "# Drop 396 male rows using the specified ratio\n",
    "male_data_dropped = drop_rows_by_ratio(maledata, 396, 4, 3)\n",
    "print(f\"Length of male data after dropping rows: {len(male_data_dropped)}\")\n",
    "\n",
    "# Drop 408 female rows using the specified ratio\n",
    "female_data_dropped = drop_rows_by_ratio(femaledata, 408, 4, 3)\n",
    "print(f\"Length of female data after dropping rows: {len(female_data_dropped)}\")\n",
    "\n",
    "# Verify the number of rows dropped\n",
    "print(f\"Number of male rows dropped: {len(maledata) - len(male_data_dropped)}\")\n",
    "print(f\"Number of female rows dropped: {len(femaledata) - len(female_data_dropped)}\")\n",
    "\n",
    "# Save the datasets to separate CSV files\n",
    "male_data_dropped.to_csv('male_data_dropped.csv', index=False)\n",
    "female_data_dropped.to_csv('female_data_dropped.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original metadata length: 2298\n",
      "Metadata length after removing rows with missing gender: 2298\n",
      "Length of male data after dropping rows: 345\n",
      "Length of female data after dropping rows: 345\n",
      "Number of male rows dropped: 396\n",
      "Number of female rows dropped: 408\n",
      "Length of final dataset after concatenation: 690\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "print(f\"Original metadata length: {len(metadata)}\")\n",
    "\n",
    "# Remove rows with missing gender (represented as empty string ' ')\n",
    "metadata = metadata[metadata['gender'] != ' ']\n",
    "print(f\"Metadata length after removing rows with missing gender: {len(metadata)}\")\n",
    "\n",
    "# Filter the data by gender\n",
    "maledata = metadata[metadata['gender'] == 'MALE']\n",
    "femaledata = metadata[metadata['gender'] == 'FEMALE']\n",
    "\n",
    "# Define the function to drop specific numbers of rows based on diagnostic values\n",
    "def drop_specific_rows(data, drop_counts):\n",
    "    indices_to_drop = []\n",
    "    for diagnostic, count in drop_counts.items():\n",
    "        diagnostic_indices = data[data['diagnostic'] == diagnostic].index[:count]\n",
    "        indices_to_drop.extend(diagnostic_indices)\n",
    "    return data.drop(indices_to_drop)\n",
    "\n",
    "# Drop 396 male rows: 19 MEL, 308 BCC, 69 SCC\n",
    "male_drop_counts = {'MEL': 16, 'BCC': 306, 'SCC': 71, 'ACK': 3}\n",
    "male_data_dropped = drop_specific_rows(maledata, male_drop_counts)\n",
    "print(f\"Length of male data after dropping rows: {len(male_data_dropped)}\")\n",
    "\n",
    "# Drop 408 female rows: 20 MEL, 318 BCC, 70 SCC\n",
    "female_drop_counts = {'MEL': 19, 'BCC': 275, 'SCC': 57, 'ACK': 37, 'NEV': 13, 'SEK': 7}\n",
    "female_data_dropped = drop_specific_rows(femaledata, female_drop_counts)\n",
    "print(f\"Length of female data after dropping rows: {len(female_data_dropped)}\")\n",
    "\n",
    "# Verify the number of rows dropped\n",
    "print(f\"Number of male rows dropped: {len(maledata) - len(male_data_dropped)}\")\n",
    "print(f\"Number of female rows dropped: {len(femaledata) - len(female_data_dropped)}\")\n",
    "\n",
    "# Concatenate the resulting datasets\n",
    "final_dataset = pd.concat([male_data_dropped, female_data_dropped], ignore_index=True)\n",
    "print(f\"Length of final dataset after concatenation: {len(final_dataset)}\")\n",
    "\n",
    "# Save the final concatenated dataset to a CSV file\n",
    "final_dataset.to_csv('final_dataset.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
